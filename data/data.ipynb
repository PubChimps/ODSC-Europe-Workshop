{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODSC Workshop Part 1 - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure tensorflow is version 2.0.0\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download examples of TensorFlow and Pytorch code in the cell below. An example is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/PubChimps/ODSC-Europe-Workshop/blob/master/data/dlzip.npz.zip?raw=true'\n",
    "r = requests.get(url)\n",
    "open('./dlzip.npz.zip', 'wb').write(r.content)\n",
    "zippedfile = zipfile.ZipFile('./dlzip.npz.zip')\n",
    "zippedfile.extractall()\n",
    "dataset = np.load('dlzip.npz', allow_pickle = True)\n",
    "dataset = dataset.f.arr_0\n",
    "\n",
    "print(dataset[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will strip the code of stopwords and encode the labels, the previous example is reprinted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = dataset[:,0]\n",
    "stopwords = ['tf', 'the', 'torch', 'keras', 'tensor', 'tensorflow', 'pytorch']\n",
    "for i in range(len(code)):\n",
    "    code [i] = re.sub(r'\\b\\w{1,1}\\b', '', code[i])\n",
    "    for word in stopwords:\n",
    "        if word in code[i]:\n",
    "            code[i] = code[i].replace(word,'')\n",
    "            \n",
    "labels = []\n",
    "for example in dataset:\n",
    "    if example[1] == 'tensorflow':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "print(code[100],'\\n',labels[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow 2.0's Keras library has function to easily tokenize and encode data for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=54483)\n",
    "tokenizer.fit_on_texts(code)\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "maxlen = 5000\n",
    "\n",
    "code_train = code[:9180]\n",
    "code_test = code[9180:]\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(code_train)\n",
    "X_test = tokenizer.texts_to_sequences(code_test)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "y_train = np.array(labels[:9180]).reshape(9180,1)\n",
    "y_test = np.array(labels[9180:]).reshape(2295,1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras' tokenizer indexes the code samples. In the example below you can see the first element's first 20 attributes in the tokenized data is a 7 and the first word in the example is 'import,' which is indexed to a 7 in tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[100][:20],'\\n',y_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code[100], '\\n\\n',tokenizer.word_index['import'], '\\n',tokenizer.word_index['flow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the preprocessed data for part 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)\n",
    "\n",
    "np.save('code.npy', code)\n",
    "np.save('labels.npy', labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
